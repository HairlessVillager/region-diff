use crate::compress::CompressionType;
use crate::mca::ChunkNbt;
use crate::util::parallel::{parallel_process, parallel_process_with_cost_estimator};
use crate::util::{IXZ, create_chunk_ixz_iter};
use crate::{
    diff::{Diff, base::BlobDiff, nbt::ChunkDiff},
    mca::{ChunkWithTimestamp, LazyChunk, MCABuilder, MCAReader},
    util::{fastnbt_deserialize as de, fastnbt_serialize as ser},
};
use bincode::{Decode, Encode};
use log::{Level, log_enabled};
use std::sync::Arc;
use std::time::Duration;

/// Diff for ChunkWithTimestamp.
///
/// In this module, we say there are three types for ChunkWithTimestamp:
/// - NotExists: Not yet generated by Minecraft, so it does not contain timestamp or nbt data.
/// - Small: A chunk with small nbt data size, so it contains timestamp and nbt data.
/// - Large: A chunk with large nbt data size. It's so large that the nbt data saved in a
/// extra .mcc file. It only contains timestamp.
#[derive(Debug, Clone, Encode, Decode)]
enum ChunkWithTimestampDiff {
    /// NotExists -> NotExists
    BothNotExist,
    /// NotExists -> Small
    CreateSmall(i32, BlobDiff),
    /// Small -> NotExists
    DeleteSmall(i32, BlobDiff),
    /// Small -> Small with changed timestamp
    UpdateSmall(i32, ChunkDiff),
    /// NotExists -> Large
    CreateLarge(i32),
    /// Large -> NotExists
    DeleteLarge(i32),
    /// Large -> Large with changed timestamp
    UpdateLarge(i32),
    /// Small -> Large
    SmallToLarge(i32, BlobDiff),
    /// Large -> Small
    LargeToSmall(i32, BlobDiff),
    /// Small -> Small or Large -> Large with same timestamp
    UpdateWtihNoChange,
}
impl ChunkWithTimestampDiff {
    pub fn get_description(&self) -> String {
        match self {
            ChunkWithTimestampDiff::BothNotExist => "report both old chunk and new chunk not exist",
            ChunkWithTimestampDiff::CreateSmall(_, _) => "is a create small diff",
            ChunkWithTimestampDiff::DeleteSmall(_, _) => "is a delete small diff",
            ChunkWithTimestampDiff::UpdateSmall(_, _) => "is a update small diff",
            ChunkWithTimestampDiff::UpdateWtihNoChange => {
                "report there's no change between old chunk and new chunk"
            }
            ChunkWithTimestampDiff::CreateLarge(_) => "is a create large diff",
            ChunkWithTimestampDiff::DeleteLarge(_) => "is a delete large diff",
            ChunkWithTimestampDiff::UpdateLarge(_) => "is a update large diff",
            ChunkWithTimestampDiff::SmallToLarge(_, _) => "is a small to large diff",
            ChunkWithTimestampDiff::LargeToSmall(_, _) => "is a large to small diff",
        }
        .to_string()
    }
}
#[derive(Debug, Clone, Encode, Decode)]
pub struct MCADiff {
    chunks: Vec<ChunkWithTimestampDiff>,
}

fn log_cost_statistics<R>(result: &[(IXZ, R, Option<Duration>)]) {
    let len = result.len();
    let mut sorted_costs = result
        .iter()
        .map(|(ixz, _, duration)| (ixz, duration))
        .collect::<Vec<_>>();
    sorted_costs.sort_by(|(_, a), (_, b)| b.cmp(a));

    let total_cost = sorted_costs.iter().map(|e| e.1.unwrap()).sum::<Duration>();
    log::debug!(
        "time costs stat:\n- total {:?}\n- avg   {:?}\n- p100  {:?}\n- p99   {:?}\n- p95   {:?}\n- p50   {:?}",
        total_cost,
        total_cost / len as u32,
        sorted_costs[0].1.unwrap(),
        sorted_costs[len / 100].1.unwrap(),
        sorted_costs[len / 20].1.unwrap(),
        sorted_costs[len / 2].1.unwrap(),
    );

    log::debug!(
        "time costs top 8:\n{}",
        sorted_costs[0..8]
            .iter()
            .map(|((i, x, z), d)| format!("- chunk {} ({}, {}) (cost {:?})", i, x, z, d.unwrap()))
            .collect::<Vec<_>>()
            .join("\n")
    );
}

fn enable_cost_stat() -> bool {
    log_enabled!(Level::Debug)
}

impl Diff<Vec<u8>> for MCADiff {
    fn from_compare(old: &Vec<u8>, new: &Vec<u8>) -> Self {
        let reader_old = Arc::new(MCAReader::from_bytes(old).unwrap());
        let reader_new = Arc::new(MCAReader::from_bytes(new).unwrap());

        let results = parallel_process_with_cost_estimator(
            create_chunk_ixz_iter(),
            |(_, x, z)| {
                let old_ts = reader_old.get_timestamp(*x, *z);
                let new_ts = reader_new.get_timestamp(*x, *z);
                let ts_diff = new_ts as i32 - old_ts as i32;

                let chunk = match (old_ts, new_ts, ts_diff) {
                    (0, 0, _) => ChunkWithTimestampDiff::BothNotExist,
                    (_, _, 0) => ChunkWithTimestampDiff::UpdateWtihNoChange,
                    _ => {
                        let old = reader_old.get_chunk_lazily(*x, *z);
                        let new = reader_new.get_chunk_lazily(*x, *z);
                        match (old, new) {
                            (LazyChunk::Unloaded, _) => panic!("old chunk is unloaded"),
                            (_, LazyChunk::Unloaded) => panic!("new chunk is unloaded"),
                            (LazyChunk::NotExists, LazyChunk::NotExists) => {
                                ChunkWithTimestampDiff::BothNotExist
                            }
                            (LazyChunk::NotExists, LazyChunk::Some(chunk)) => match &chunk.nbt {
                                ChunkNbt::Large => {
                                    ChunkWithTimestampDiff::CreateLarge(chunk.timestamp as i32)
                                }
                                ChunkNbt::Small(nbt) => ChunkWithTimestampDiff::CreateSmall(
                                    chunk.timestamp as i32,
                                    BlobDiff::from_compare(&Vec::new(), &nbt),
                                ),
                            },
                            (LazyChunk::Some(chunk), LazyChunk::NotExists) => match &chunk.nbt {
                                ChunkNbt::Large => {
                                    ChunkWithTimestampDiff::DeleteLarge(-(chunk.timestamp as i32))
                                }
                                ChunkNbt::Small(nbt) => ChunkWithTimestampDiff::DeleteSmall(
                                    -(chunk.timestamp as i32),
                                    BlobDiff::from_compare(&nbt, &Vec::new()),
                                ),
                            },
                            (LazyChunk::Some(chunk_old), LazyChunk::Some(chunk_new)) => {
                                let ts_diff =
                                    chunk_new.timestamp as i32 - chunk_old.timestamp as i32;
                                if ts_diff == 0 {
                                    ChunkWithTimestampDiff::UpdateWtihNoChange
                                } else {
                                    match (&chunk_old.nbt, &chunk_new.nbt) {
                                        (ChunkNbt::Large, ChunkNbt::Large) => {
                                            ChunkWithTimestampDiff::UpdateLarge(ts_diff)
                                        }
                                        (ChunkNbt::Small(old), ChunkNbt::Small(new)) => {
                                            ChunkWithTimestampDiff::UpdateSmall(
                                                ts_diff,
                                                ChunkDiff::from_compare(&de(&old), &de(&new)),
                                            )
                                        }
                                        (ChunkNbt::Small(old), ChunkNbt::Large) => {
                                            ChunkWithTimestampDiff::SmallToLarge(
                                                ts_diff,
                                                BlobDiff::from_delete(&old),
                                            )
                                        }
                                        (ChunkNbt::Large, ChunkNbt::Small(new)) => {
                                            ChunkWithTimestampDiff::SmallToLarge(
                                                ts_diff,
                                                BlobDiff::from_create(&new),
                                            )
                                        }
                                    }
                                }
                            }
                        }
                    }
                };
                chunk
            },
            |(_, x, z)| {
                let old_ts = reader_old.get_timestamp(*x, *z);
                let new_ts = reader_new.get_timestamp(*x, *z);
                let ts_diff = new_ts as i32 - old_ts as i32;

                let chunk = match (old_ts, new_ts, ts_diff) {
                    (0, 0, _) => 0,
                    (_, _, 0) => 0,
                    _ => {
                        let old = reader_old.get_chunk_lazily(*x, *z);
                        let new = reader_new.get_chunk_lazily(*x, *z);
                        match (old, new) {
                            (LazyChunk::Some(chunk_old), LazyChunk::Some(chunk_new)) => {
                                let old = &chunk_old.nbt;
                                let new = &chunk_new.nbt;
                                match (old, new) {
                                    (ChunkNbt::Small(old), ChunkNbt::Small(new)) => {
                                        use std::cmp::{max, min};
                                        let old = old.len();
                                        let new = new.len();
                                        max(old, new) - min(old, new)
                                    }
                                    _ => 0,
                                }
                            }
                            _ => 0,
                        }
                    }
                };
                chunk
            },
        );

        if enable_cost_stat() {
            log_cost_statistics(&results);
        }

        let mut chunks = vec![ChunkWithTimestampDiff::BothNotExist; 1024];
        for ((i, _, _), chunk, _) in results {
            chunks[i] = chunk;
        }

        Self { chunks }
    }

    fn from_squash(base: &Self, squashing: &Self) -> Self {
        let results = parallel_process(create_chunk_ixz_iter(), |(i, _, _)| {
            let base_diff = &base.chunks[*i];
            let squashing_diff = &squashing.chunks[*i];

            let squashed = match base_diff {
                // any state --> NotExists --> any state
                ChunkWithTimestampDiff::BothNotExist => match squashing_diff {
                    ChunkWithTimestampDiff::BothNotExist => ChunkWithTimestampDiff::BothNotExist,
                    ChunkWithTimestampDiff::CreateSmall(s_ts_diff, s_blob_diff) => {
                        ChunkWithTimestampDiff::CreateSmall(*s_ts_diff, s_blob_diff.clone())
                    }
                    ChunkWithTimestampDiff::CreateLarge(s_ts_diff) => {
                        ChunkWithTimestampDiff::CreateLarge(*s_ts_diff)
                    }
                    _ => panic!(
                        "impossible case: base diff {}, while squashing diff {}",
                        base_diff.get_description(),
                        squashing_diff.get_description()
                    ),
                },
                ChunkWithTimestampDiff::DeleteLarge(b_ts_diff) => match squashing_diff {
                    ChunkWithTimestampDiff::BothNotExist => {
                        ChunkWithTimestampDiff::DeleteLarge(*b_ts_diff)
                    }
                    ChunkWithTimestampDiff::CreateSmall(s_ts_diff, s_blob_diff) => {
                        ChunkWithTimestampDiff::LargeToSmall(
                            b_ts_diff + s_ts_diff,
                            s_blob_diff.clone(),
                        )
                    }
                    ChunkWithTimestampDiff::CreateLarge(s_ts_diff) => {
                        ChunkWithTimestampDiff::UpdateLarge(b_ts_diff + s_ts_diff)
                    }
                    _ => panic!(
                        "impossible case: base diff {}, while squashing diff {}",
                        base_diff.get_description(),
                        squashing_diff.get_description()
                    ),
                },
                ChunkWithTimestampDiff::DeleteSmall(b_ts_diff, b_blob_diff) => match squashing_diff
                {
                    ChunkWithTimestampDiff::BothNotExist => {
                        ChunkWithTimestampDiff::DeleteSmall(*b_ts_diff, b_blob_diff.clone())
                    }
                    ChunkWithTimestampDiff::CreateSmall(s_ts_diff, s_blob_diff) => {
                        ChunkWithTimestampDiff::UpdateSmall(
                            b_ts_diff + s_ts_diff,
                            ChunkDiff::from_compare(
                                &de(b_blob_diff.get_old_text()),
                                &de(s_blob_diff.get_new_text()),
                            ),
                        )
                    }
                    ChunkWithTimestampDiff::CreateLarge(s_ts_diff) => {
                        ChunkWithTimestampDiff::SmallToLarge(
                            b_ts_diff + s_ts_diff,
                            b_blob_diff.clone(),
                        )
                    }
                    _ => panic!(
                        "impossible case: base diff {}, while squashing diff {}",
                        base_diff.get_description(),
                        squashing_diff.get_description()
                    ),
                },

                // any state --> Small --> any state
                ChunkWithTimestampDiff::UpdateSmall(b_ts_diff, b_chunk_diff) => {
                    match squashing_diff {
                        ChunkWithTimestampDiff::UpdateWtihNoChange => {
                            ChunkWithTimestampDiff::UpdateSmall(*b_ts_diff, b_chunk_diff.clone())
                        }
                        ChunkWithTimestampDiff::UpdateSmall(s_ts_diff, s_blob_diff) => {
                            ChunkWithTimestampDiff::UpdateSmall(
                                b_ts_diff + s_ts_diff,
                                ChunkDiff::from_squash(b_chunk_diff, s_blob_diff),
                            )
                        }
                        ChunkWithTimestampDiff::DeleteSmall(s_ts_diff, s_blob_diff) => {
                            ChunkWithTimestampDiff::DeleteSmall(
                                b_ts_diff + s_ts_diff,
                                BlobDiff::from_compare(
                                    &ser(&b_chunk_diff.revert(&de(s_blob_diff.get_old_text()))),
                                    s_blob_diff.get_new_text(),
                                ),
                            )
                        }
                        ChunkWithTimestampDiff::SmallToLarge(s_ts_diff, s_blob_diff) => {
                            ChunkWithTimestampDiff::SmallToLarge(
                                b_ts_diff + s_ts_diff,
                                BlobDiff::from_compare(
                                    &ser(&b_chunk_diff.revert(&de(s_blob_diff.get_old_text()))),
                                    s_blob_diff.get_new_text(),
                                ),
                            )
                        }
                        _ => panic!(
                            "impossible case: base diff {}, while squashing diff {}",
                            base_diff.get_description(),
                            squashing_diff.get_description()
                        ),
                    }
                }
                ChunkWithTimestampDiff::CreateSmall(b_ts_diff, b_blob_diff) => match squashing_diff
                {
                    ChunkWithTimestampDiff::UpdateWtihNoChange => {
                        ChunkWithTimestampDiff::CreateSmall(*b_ts_diff, b_blob_diff.clone())
                    }
                    ChunkWithTimestampDiff::UpdateSmall(s_ts_diff, s_chunk_diff) => {
                        ChunkWithTimestampDiff::CreateSmall(
                            b_ts_diff + s_ts_diff,
                            BlobDiff::from_compare(
                                b_blob_diff.get_old_text(),
                                &ser(&s_chunk_diff.patch(&de(b_blob_diff.get_new_text()))),
                            ),
                        )
                    }
                    ChunkWithTimestampDiff::DeleteSmall(..) => ChunkWithTimestampDiff::BothNotExist,
                    ChunkWithTimestampDiff::SmallToLarge(s_ts_diff, _) => {
                        ChunkWithTimestampDiff::CreateLarge(*s_ts_diff)
                    }
                    _ => panic!(
                        "impossible case: base diff {}, while squashing diff {}",
                        base_diff.get_description(),
                        squashing_diff.get_description()
                    ),
                },
                ChunkWithTimestampDiff::LargeToSmall(b_ts_diff, b_blob_diff) => {
                    match squashing_diff {
                        ChunkWithTimestampDiff::UpdateWtihNoChange => {
                            ChunkWithTimestampDiff::LargeToSmall(*b_ts_diff, b_blob_diff.clone())
                        }
                        ChunkWithTimestampDiff::UpdateSmall(s_ts_diff, s_chunk_diff) => {
                            ChunkWithTimestampDiff::LargeToSmall(
                                b_ts_diff + s_ts_diff,
                                BlobDiff::from_compare(
                                    b_blob_diff.get_old_text(),
                                    &ser(&s_chunk_diff.patch(&de(b_blob_diff.get_new_text()))),
                                ),
                            )
                        }
                        ChunkWithTimestampDiff::DeleteSmall(s_ts_diff, _) => {
                            ChunkWithTimestampDiff::DeleteLarge(b_ts_diff + s_ts_diff)
                        }
                        ChunkWithTimestampDiff::SmallToLarge(s_ts_diff, _) => {
                            ChunkWithTimestampDiff::UpdateLarge(b_ts_diff + s_ts_diff)
                        }
                        _ => panic!(
                            "impossible case: base diff {}, while squashing diff {}",
                            base_diff.get_description(),
                            squashing_diff.get_description()
                        ),
                    }
                }

                // any state --> Large --> any state
                ChunkWithTimestampDiff::CreateLarge(b_ts_diff) => match squashing_diff {
                    ChunkWithTimestampDiff::UpdateWtihNoChange => {
                        ChunkWithTimestampDiff::CreateLarge(*b_ts_diff)
                    }
                    ChunkWithTimestampDiff::UpdateLarge(s_ts_diff) => {
                        ChunkWithTimestampDiff::CreateLarge(b_ts_diff + s_ts_diff)
                    }
                    ChunkWithTimestampDiff::DeleteLarge(_) => ChunkWithTimestampDiff::BothNotExist,
                    ChunkWithTimestampDiff::LargeToSmall(s_ts_diff, s_blob_diff) => {
                        ChunkWithTimestampDiff::CreateSmall(
                            b_ts_diff + s_ts_diff,
                            s_blob_diff.clone(),
                        )
                    }
                    _ => panic!(
                        "impossible case: base diff {}, while squashing diff {}",
                        base_diff.get_description(),
                        squashing_diff.get_description()
                    ),
                },
                ChunkWithTimestampDiff::UpdateLarge(b_ts_diff) => match squashing_diff {
                    ChunkWithTimestampDiff::UpdateWtihNoChange => {
                        ChunkWithTimestampDiff::UpdateLarge(*b_ts_diff)
                    }
                    ChunkWithTimestampDiff::UpdateLarge(s_ts_diff) => {
                        ChunkWithTimestampDiff::UpdateLarge(b_ts_diff + s_ts_diff)
                    }
                    ChunkWithTimestampDiff::DeleteLarge(s_ts_diff) => {
                        ChunkWithTimestampDiff::DeleteLarge(b_ts_diff + s_ts_diff)
                    }
                    ChunkWithTimestampDiff::LargeToSmall(s_ts_diff, s_blob_diff) => {
                        ChunkWithTimestampDiff::LargeToSmall(
                            b_ts_diff + s_ts_diff,
                            s_blob_diff.clone(),
                        )
                    }
                    _ => panic!(
                        "impossible case: base diff {}, while squashing diff {}",
                        base_diff.get_description(),
                        squashing_diff.get_description()
                    ),
                },
                ChunkWithTimestampDiff::SmallToLarge(b_ts_diff, b_blob_diff) => {
                    match squashing_diff {
                        ChunkWithTimestampDiff::UpdateWtihNoChange => {
                            ChunkWithTimestampDiff::SmallToLarge(*b_ts_diff, b_blob_diff.clone())
                        }
                        ChunkWithTimestampDiff::UpdateLarge(s_ts_diff) => {
                            ChunkWithTimestampDiff::SmallToLarge(
                                b_ts_diff + s_ts_diff,
                                b_blob_diff.clone(),
                            )
                        }
                        ChunkWithTimestampDiff::DeleteLarge(s_ts_diff) => {
                            ChunkWithTimestampDiff::DeleteSmall(
                                b_ts_diff + s_ts_diff,
                                b_blob_diff.clone(),
                            )
                        }
                        ChunkWithTimestampDiff::LargeToSmall(s_ts_diff, s_blob_diff) => {
                            ChunkWithTimestampDiff::UpdateSmall(
                                b_ts_diff + s_ts_diff,
                                ChunkDiff::from_compare(
                                    &de(b_blob_diff.get_old_text()),
                                    &de(s_blob_diff.get_new_text()),
                                ),
                            )
                        }
                        _ => panic!(
                            "impossible case: base diff {}, while squashing diff {}",
                            base_diff.get_description(),
                            squashing_diff.get_description()
                        ),
                    }
                }

                // no change
                ChunkWithTimestampDiff::UpdateWtihNoChange => match squashing_diff {
                    ChunkWithTimestampDiff::UpdateWtihNoChange
                    | ChunkWithTimestampDiff::UpdateLarge(..)
                    | ChunkWithTimestampDiff::DeleteLarge(..)
                    | ChunkWithTimestampDiff::UpdateSmall(..)
                    | ChunkWithTimestampDiff::DeleteSmall(..)
                    | ChunkWithTimestampDiff::SmallToLarge(..)
                    | ChunkWithTimestampDiff::LargeToSmall(..) => base_diff.clone(),
                    _ => panic!(
                        "impossible case: base diff {}, while squashing diff {}",
                        base_diff.get_description(),
                        squashing_diff.get_description()
                    ),
                },
            };
            squashed
        });

        if enable_cost_stat() {
            log_cost_statistics(&results);
        }

        let mut squashed_chunks = vec![ChunkWithTimestampDiff::BothNotExist; 1024];
        for ((i, _, _), chunk, _) in results {
            squashed_chunks[i] = chunk;
        }

        Self {
            chunks: squashed_chunks,
        }
    }

    fn patch(&self, old: &Vec<u8>) -> Vec<u8> {
        let reader = Arc::new(MCAReader::from_bytes(old).unwrap());
        let enable_cost_stat = log_enabled!(Level::Debug);

        let results = parallel_process(create_chunk_ixz_iter(), |(i, x, z)| {
            let old_chunk = reader.get_chunk_lazily(*x, *z);
            let chunk_diff = &self.chunks[*i];

            let new_chunk = match old_chunk {
                LazyChunk::Unloaded => panic!("old chunk is unloaded"),
                LazyChunk::NotExists => match chunk_diff {
                    ChunkWithTimestampDiff::BothNotExist => None,
                    ChunkWithTimestampDiff::CreateSmall(ts_diff, chunk_diff) => {
                        Some(ChunkWithTimestamp {
                            timestamp: *ts_diff as u32,
                            nbt: ChunkNbt::Small(chunk_diff.patch(&Vec::new())),
                        })
                    }
                    ChunkWithTimestampDiff::CreateLarge(ts_diff) => {
                        assert!(*ts_diff != 0);
                        Some(ChunkWithTimestamp {
                            timestamp: *ts_diff as u32,
                            nbt: ChunkNbt::Large,
                        })
                    }
                    _ => panic!(
                        "Invalid diff for non-existing chunk: {}",
                        chunk_diff.get_description()
                    ),
                },
                LazyChunk::Some(old_chunk) => match &old_chunk.nbt {
                    ChunkNbt::Small(nbt) => match chunk_diff {
                        ChunkWithTimestampDiff::DeleteSmall(..) => None,
                        ChunkWithTimestampDiff::UpdateSmall(ts_diff, chunk_diff) => {
                            Some(ChunkWithTimestamp {
                                timestamp: old_chunk
                                    .timestamp
                                    .checked_add_signed(*ts_diff)
                                    .expect("timestamp overflow"),
                                nbt: ChunkNbt::Small(ser(&chunk_diff.patch(&de(&nbt)))),
                            })
                        }
                        ChunkWithTimestampDiff::SmallToLarge(ts_diff, _) => {
                            Some(ChunkWithTimestamp {
                                timestamp: old_chunk
                                    .timestamp
                                    .checked_add_signed(*ts_diff)
                                    .expect("timestamp overflow"),
                                nbt: ChunkNbt::Large,
                            })
                        }
                        ChunkWithTimestampDiff::UpdateWtihNoChange => Some(old_chunk.clone()),
                        _ => panic!(
                            "Invalid diff for existing small chunk: {}",
                            chunk_diff.get_description()
                        ),
                    },
                    ChunkNbt::Large => match chunk_diff {
                        ChunkWithTimestampDiff::DeleteLarge(..) => None,
                        ChunkWithTimestampDiff::UpdateLarge(ts_diff) => Some(ChunkWithTimestamp {
                            timestamp: old_chunk
                                .timestamp
                                .checked_add_signed(*ts_diff)
                                .expect("timestamp overflow"),
                            nbt: ChunkNbt::Large,
                        }),
                        ChunkWithTimestampDiff::LargeToSmall(ts_diff, blob_diff) => {
                            Some(ChunkWithTimestamp {
                                timestamp: old_chunk
                                    .timestamp
                                    .checked_add_signed(*ts_diff)
                                    .expect("timestamp overflow"),
                                nbt: ChunkNbt::Small(blob_diff.patch0()),
                            })
                        }
                        ChunkWithTimestampDiff::UpdateWtihNoChange => Some(old_chunk.clone()),
                        _ => panic!(
                            "Invalid diff for existing large chunk: {}",
                            chunk_diff.get_description()
                        ),
                    },
                },
            };
            new_chunk
        });

        if enable_cost_stat {
            log_cost_statistics(&results);
        }

        let mut builder = MCABuilder::new();
        for ((_, x, z), new_chunk, _) in &results {
            if let Some(chunk) = new_chunk {
                builder.set_chunk(*x, *z, &chunk);
            }
        }

        builder.to_bytes(CompressionType::Zlib)
    }

    fn revert(&self, new: &Vec<u8>) -> Vec<u8> {
        let reader = Arc::new(MCAReader::from_bytes(new).unwrap());
        let enable_cost_stat = log_enabled!(Level::Debug);

        let results = parallel_process(create_chunk_ixz_iter(), |(i, x, z)| {
            let new_chunk = reader.get_chunk_lazily(*x, *z);
            let chunk_diff = &self.chunks[*i];

            let old_chunk = match new_chunk {
                LazyChunk::Unloaded => panic!("new chunk is unloaded"),
                LazyChunk::NotExists => match chunk_diff {
                    ChunkWithTimestampDiff::BothNotExist => None,
                    ChunkWithTimestampDiff::DeleteSmall(ts_diff, blob_diff) => {
                        Some(ChunkWithTimestamp {
                            timestamp: -ts_diff as u32,
                            nbt: ChunkNbt::Small(blob_diff.revert0()),
                        })
                    }
                    ChunkWithTimestampDiff::DeleteLarge(ts_diff) => Some(ChunkWithTimestamp {
                        timestamp: -ts_diff as u32,
                        nbt: ChunkNbt::Large,
                    }),
                    _ => panic!(
                        "Invalid diff for non-existing chunk: {}",
                        chunk_diff.get_description()
                    ),
                },
                LazyChunk::Some(new_chunk) => match &new_chunk.nbt {
                    ChunkNbt::Small(nbt) => match chunk_diff {
                        ChunkWithTimestampDiff::CreateSmall(..) => None,
                        ChunkWithTimestampDiff::UpdateSmall(ts_diff, chunk_diff) => {
                            Some(ChunkWithTimestamp {
                                timestamp: new_chunk
                                    .timestamp
                                    .checked_add_signed(-*ts_diff)
                                    .expect("timestamp overflow"),
                                nbt: ChunkNbt::Small(ser(&chunk_diff.revert(&de(&nbt)))),
                            })
                        }
                        ChunkWithTimestampDiff::LargeToSmall(ts_diff, _) => {
                            Some(ChunkWithTimestamp {
                                timestamp: new_chunk
                                    .timestamp
                                    .checked_add_signed(-*ts_diff)
                                    .expect("timestamp overflow"),
                                nbt: ChunkNbt::Large,
                            })
                        }
                        ChunkWithTimestampDiff::UpdateWtihNoChange => Some(new_chunk.clone()),
                        _ => panic!(
                            "Invalid diff for existing small chunk: {}",
                            chunk_diff.get_description()
                        ),
                    },
                    ChunkNbt::Large => match chunk_diff {
                        ChunkWithTimestampDiff::CreateLarge(_) => None,
                        ChunkWithTimestampDiff::UpdateLarge(ts_diff) => Some(ChunkWithTimestamp {
                            timestamp: new_chunk
                                .timestamp
                                .checked_add_signed(-*ts_diff)
                                .expect("timestamp overflow"),
                            nbt: ChunkNbt::Large,
                        }),
                        ChunkWithTimestampDiff::SmallToLarge(ts_diff, blob_diff) => {
                            Some(ChunkWithTimestamp {
                                timestamp: new_chunk
                                    .timestamp
                                    .checked_add_signed(-*ts_diff)
                                    .expect("timestamp overflow"),
                                nbt: ChunkNbt::Small(blob_diff.revert0()),
                            })
                        }
                        ChunkWithTimestampDiff::UpdateWtihNoChange => Some(new_chunk.clone()),
                        _ => panic!(
                            "Invalid diff for existing large chunk: {}",
                            chunk_diff.get_description()
                        ),
                    },
                },
            };
            old_chunk
        });

        if enable_cost_stat {
            log_cost_statistics(&results);
        }

        let mut builder = MCABuilder::new();
        for ((_, x, z), old_chunk, _) in &results {
            if let Some(chunk) = old_chunk {
                builder.set_chunk(*x, *z, &chunk);
            }
        }

        builder.to_bytes(CompressionType::Zlib)
    }
}

#[cfg(test)]
mod tests {
    use std::{fs, path::PathBuf};

    use crate::{
        config::{Config, with_test_config},
        mca::{LazyChunk, MCAReader},
        util::test::{all_file_iter, assert_mca_eq, rearranged_nbt},
    };

    use super::*;

    static TEST_CONFIG: Config = Config {
        log_config: crate::config::LogConfig::NoLog,
        threads: 16,
    };

    #[test]
    #[ignore = "replace test mca files"]
    fn test_mca_timestamp_nbt() {
        with_test_config(TEST_CONFIG.clone(), || {
            let reader_old = MCAReader::from_file(
                &PathBuf::from(
                    "./resources/test-payload/region/mca/hairlessvillager-0/20250511.mca",
                ),
                false,
            )
            .unwrap();
            let reader_new = MCAReader::from_file(
                &PathBuf::from(
                    "./resources/test-payload/region/mca/hairlessvillager-0/20250512.mca",
                ),
                false,
            )
            .unwrap();
            let mut ts_changed_chunk_count = 0;
            let mut ts_unchanged_chunk_count = 0;
            for (_, x, z) in create_chunk_ixz_iter() {
                let (timestamp_old, nbt_old) = match reader_old.get_chunk_lazily(x, z) {
                    LazyChunk::Some(chunk) => {
                        if let ChunkNbt::Small(nbt) = &chunk.nbt {
                            (chunk.timestamp, rearranged_nbt(nbt).unwrap())
                        } else {
                            panic!(concat!(
                                "This chunk is too large to save in .mca file, so it do not contains any bytes. ",
                                "If you are testing, use another .mca file instead.",
                            ))
                        }
                    }
                    _ => panic!("chunk should loaded"),
                };
                let (timestamp_new, nbt_new) = match reader_new.get_chunk_lazily(x, z) {
                    LazyChunk::Some(chunk) => {
                        if let ChunkNbt::Small(nbt) = &chunk.nbt {
                            (chunk.timestamp, rearranged_nbt(nbt).unwrap())
                        } else {
                            panic!(concat!(
                                "This chunk is too large to save in .mca file, so it do not contains any bytes. ",
                                "If you are testing, use another .mca file instead.",
                            ))
                        }
                    }
                    _ => panic!("chunk should loaded"),
                };
                if timestamp_old == timestamp_new {
                    ts_unchanged_chunk_count += 1;
                    assert_eq!(nbt_old, nbt_new);
                } else {
                    ts_changed_chunk_count += 1;
                    assert_ne!(nbt_old, nbt_new);
                }
            }
            assert!(ts_changed_chunk_count > 20);
            assert!(ts_unchanged_chunk_count > 20);
        });
    }
    #[test]
    fn test_diff_patch_revert() {
        with_test_config(TEST_CONFIG.clone(), || {
            for paths in all_file_iter(crate::FileType::RegionMca) {
                for window in paths.collect::<Vec<_>>().windows(2) {
                    let old = fs::read(window[0].clone()).unwrap();
                    let new = fs::read(window[1].clone()).unwrap();
                    let diff = MCADiff::from_compare(&old, &new);
                    let patched_old = diff.patch(&old);
                    let reverted_new = diff.revert(&new);
                    assert_mca_eq(&new, &patched_old);
                    assert_mca_eq(&old, &reverted_new);
                    break;
                }
                break;
            }
        });
    }
    #[test]
    fn test_diff_squash() {
        with_test_config(TEST_CONFIG.clone(), || {
            for paths in all_file_iter(crate::FileType::RegionMca) {
                for window in paths.collect::<Vec<_>>().windows(3) {
                    let v0 = fs::read(window[0].clone()).unwrap();
                    let v1 = fs::read(window[1].clone()).unwrap();
                    let v2 = fs::read(window[2].clone()).unwrap();
                    let diff_v01 = MCADiff::from_compare(&v0, &v1);
                    let diff_v12 = MCADiff::from_compare(&v1, &v2);
                    let squashed_diff = MCADiff::from_squash(&diff_v01, &diff_v12);
                    let patched_v0 = squashed_diff.patch(&v0);
                    let reverted_v2 = squashed_diff.revert(&v2);
                    assert_mca_eq(&v2, &patched_v0);
                    assert_mca_eq(&v0, &reverted_v2);
                }
            }
        });
    }
    #[test]
    #[ignore = "use benchmark test"]
    fn test_time_cost() {
        // The next performance hotspot is the diff of sections, but since the
        // current performance is already good enough, I don't plan to
        // optimize this area in the near future.
        with_test_config(TEST_CONFIG.clone(), || {
            log::debug!("reading files...");
            let a = fs::read("./resources/mca/r.1.2.20250515.mca").unwrap();
            let b = fs::read("./resources/mca/r.1.2.20250516.mca").unwrap();
            MCADiff::from_compare(&a, &b);
        });
    }
}
